{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2130b2f2-bf4b-4faf-a01f-1b8d579f75d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "309fda01-9e84-4b1e-9023-ac59c9b9c7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "import joblib\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2845654b-70d1-46a5-b0b4-5180a7b61b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>208Tl</th>\n",
       "      <th>212BiPo</th>\n",
       "      <th>212BiTl</th>\n",
       "      <th>212Pb</th>\n",
       "      <th>212Po</th>\n",
       "      <th>216Po</th>\n",
       "      <th>220Rn</th>\n",
       "      <th>224Ra</th>\n",
       "      <th>228Ac</th>\n",
       "      <th>228Ra</th>\n",
       "      <th>...</th>\n",
       "      <th>226Ra</th>\n",
       "      <th>230Th</th>\n",
       "      <th>234Pam</th>\n",
       "      <th>234PaU</th>\n",
       "      <th>234Th</th>\n",
       "      <th>234U</th>\n",
       "      <th>238U</th>\n",
       "      <th>40K</th>\n",
       "      <th>137Cs</th>\n",
       "      <th>7Be</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>22.2</td>\n",
       "      <td>68.8</td>\n",
       "      <td>40.3</td>\n",
       "      <td>61.4</td>\n",
       "      <td>61.3</td>\n",
       "      <td>64.7</td>\n",
       "      <td>69.8</td>\n",
       "      <td>60.5</td>\n",
       "      <td>...</td>\n",
       "      <td>498.0</td>\n",
       "      <td>488.0</td>\n",
       "      <td>0.855</td>\n",
       "      <td>485.0</td>\n",
       "      <td>488.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>200.00</td>\n",
       "      <td>0.868</td>\n",
       "      <td>78.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.0</td>\n",
       "      <td>27.3</td>\n",
       "      <td>15.7</td>\n",
       "      <td>41.5</td>\n",
       "      <td>25.9</td>\n",
       "      <td>44.3</td>\n",
       "      <td>42.1</td>\n",
       "      <td>43.3</td>\n",
       "      <td>42.6</td>\n",
       "      <td>40.2</td>\n",
       "      <td>...</td>\n",
       "      <td>427.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>0.629</td>\n",
       "      <td>424.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>30.50</td>\n",
       "      <td>0.349</td>\n",
       "      <td>55.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.6</td>\n",
       "      <td>53.3</td>\n",
       "      <td>27.1</td>\n",
       "      <td>84.2</td>\n",
       "      <td>56.5</td>\n",
       "      <td>87.2</td>\n",
       "      <td>82.3</td>\n",
       "      <td>79.1</td>\n",
       "      <td>82.7</td>\n",
       "      <td>86.6</td>\n",
       "      <td>...</td>\n",
       "      <td>230.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>237.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>56.50</td>\n",
       "      <td>0.587</td>\n",
       "      <td>43.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.8</td>\n",
       "      <td>20.5</td>\n",
       "      <td>11.8</td>\n",
       "      <td>30.7</td>\n",
       "      <td>20.0</td>\n",
       "      <td>33.3</td>\n",
       "      <td>32.9</td>\n",
       "      <td>33.6</td>\n",
       "      <td>29.2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>0.417</td>\n",
       "      <td>281.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>157.00</td>\n",
       "      <td>0.212</td>\n",
       "      <td>37.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>106.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>95.8</td>\n",
       "      <td>275.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>...</td>\n",
       "      <td>215.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.345</td>\n",
       "      <td>212.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.800</td>\n",
       "      <td>59.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   208Tl  212BiPo  212BiTl  212Pb  212Po  216Po  220Rn  224Ra  228Ac  228Ra  \\\n",
       "0   23.0     42.8     22.2   68.8   40.3   61.4   61.3   64.7   69.8   60.5   \n",
       "1   16.0     27.3     15.7   41.5   25.9   44.3   42.1   43.3   42.6   40.2   \n",
       "2   29.6     53.3     27.1   84.2   56.5   87.2   82.3   79.1   82.7   86.6   \n",
       "3   11.8     20.5     11.8   30.7   20.0   33.3   32.9   33.6   29.2   30.0   \n",
       "4  106.0    172.0     95.8  275.0  168.0  257.0  297.0  289.0  291.0  275.0   \n",
       "\n",
       "   ...  226Ra  230Th  234Pam  234PaU  234Th   234U   238U     40K  137Cs   7Be  \n",
       "0  ...  498.0  488.0   0.855   485.0  488.0  532.0  530.0  200.00  0.868  78.3  \n",
       "1  ...  427.0  408.0   0.629   424.0  402.0  433.0  425.0   30.50  0.349  55.5  \n",
       "2  ...  230.0  231.0   0.353   237.0  224.0  212.0  218.0   56.50  0.587  43.2  \n",
       "3  ...  254.0  244.0   0.417   281.0  244.0  258.0  282.0  157.00  0.212  37.8  \n",
       "4  ...  215.0  205.0   0.345   212.0  203.0  225.0  204.0    1.45  1.800  59.3  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = pd.read_csv('../data/Activity.csv',skipinitialspace=True, na_values='?')\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41cf079a-99f6-41d6-8b14-3bad93eacbdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['208Tl', '212BiPo', '212BiTl', '212Pb', '212Po']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_isotopes = Y.columns.values.tolist()\n",
    "list_isotopes[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77072d53-3959-4d8c-b461-7e8bcbf2416e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:\t (4800, 8192)\n",
      "x_test shape:\t (1200, 8192)\n",
      "y_train shape:\t (4800, 41)\n",
      "y_test shape:\t (1200, 41)\n"
     ]
    }
   ],
   "source": [
    "loaded_data = np.load('../data/hpge-soil-gamma-41.npz')\n",
    "x_train = loaded_data['x_train']\n",
    "y_train = loaded_data['y_train']\n",
    "x_test = loaded_data['x_test']\n",
    "y_test = loaded_data['y_test']\n",
    "\n",
    "print('x_train shape:\\t', x_train.shape)\n",
    "print('x_test shape:\\t', x_test.shape)\n",
    "print('y_train shape:\\t', y_train.shape)\n",
    "print('y_test shape:\\t', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c80088e8-ab20-4de4-9dd5-0250541dfba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare scaling methods for mlp inputs on regression problem\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, PoissonRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fc0ce51-5381-456d-a0a1-a7116469faa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset with input and output scalers, can be none\n",
    "def get_scaled_dataset(input_scaler, output_scaler, x_train, y_train, x_test, y_test, \n",
    "                       input_scaler_path='../scaler/input_scaler.sav'):\n",
    "    x_train = x_train\n",
    "    x_test = x_test\n",
    "    y_test = y_test\n",
    "    y_train = y_train\n",
    "\n",
    "    if input_scaler is not None:\n",
    "        # fit scaler\n",
    "        input_scaler.fit(x_train)\n",
    "        # transform training dataset\n",
    "        x_train = input_scaler.transform(x_train)\n",
    "        # transform test dataset\n",
    "        x_test = input_scaler.transform(x_test)\n",
    "        # save the scaler\n",
    "        joblib.dump(input_scaler, input_scaler_path)\n",
    "    \n",
    "    if output_scaler is not None:\n",
    "        # fit scaler\n",
    "        output_scaler.fit(y_train)\n",
    "        # transform training dataset\n",
    "        y_train = output_scaler.transform(y_train)\n",
    "        # transform test dataset\n",
    "        y_test = output_scaler.transform(y_test)\n",
    "        # save the scaler\n",
    "        # joblib.dump(output_scaler, output_scaler_path)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test, output_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a5f6fd-e95c-46c8-8171-7880095422f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainy, testX, testy, output_scaler = get_scaled_dataset(MinMaxScaler(), None, x_train, y_train, x_test, y_test)\n",
    "input_shape = trainX.shape[1]\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5768408-caae-468e-b6d2-d700c230cfa3",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1631e6b5-7d31-4099-9caf-5a047c204d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "\n",
    "alphas = np.logspace(-5, 5, 100)\n",
    "epsilon = 1e-6\n",
    "\n",
    "def RidgecvMultiOutput(alpha, trainX, trainy_full, testX, testy_full):\n",
    "    \"\"\"\n",
    "    Trains a Ridge model and returns the average MAE across all outputs.\n",
    "    \"\"\"\n",
    "    model = Ridge(alpha=alpha)\n",
    "    model.fit(trainX, trainy_full)\n",
    "    pre = model.predict(testX)\n",
    "    mae_avg = mean_absolute_error(testy_full, pre)\n",
    "    return mae_avg\n",
    "\n",
    "print(\"Optimizing alpha for multi-output regression...\")\n",
    "Ridge_results_avg = []\n",
    "for a in alphas:\n",
    "    mae_avg = RidgecvMultiOutput(a, trainX, trainy, testX, testy)\n",
    "    Ridge_results_avg.append(mae_avg)\n",
    "\n",
    "min_avg_mae = min(Ridge_results_avg)\n",
    "min_index = Ridge_results_avg.index(min_avg_mae)\n",
    "best_alpha = alphas[min_index]\n",
    "print(f\"Best alpha found based on average MAE: {best_alpha}\")\n",
    "\n",
    "\n",
    "print(\"Training final multi-output model with best alpha...\")\n",
    "final_model = Ridge(alpha=best_alpha)\n",
    "final_model.fit(trainX, trainy)\n",
    "val_pre_full = final_model.predict(testX)\n",
    "results_list = []\n",
    "print(\"Calculating metrics for each output using the single trained model...\")\n",
    "\n",
    "for idx, output_name in enumerate(list_dongvi):\n",
    "    testy_output = testy[:, idx]\n",
    "    val_pre_output = val_pre_full[:, idx] \n",
    "\n",
    "    MAE = mean_absolute_error(testy_output, val_pre_output)\n",
    "    MSE = mean_squared_error(testy_output, val_pre_output)\n",
    "    RMSE = np.sqrt(MSE)\n",
    "\n",
    "    RMSLE = np.log(RMSE + epsilon) if RMSE >= 0 else np.nan \n",
    "    R2_Score = r2_score(testy_output, val_pre_output)\n",
    "    MAPE = mean_absolute_percentage_error(testy_output + epsilon, val_pre_output)\n",
    "\n",
    "    percentage_errors = np.abs((testy_output - val_pre_output) / (testy_output + epsilon))\n",
    "    count_below_threshold = np.sum(percentage_errors < 0.15)\n",
    "    percentage_below_threshold = count_below_threshold / len(testy_output) if len(testy_output) > 0 else 0\n",
    "\n",
    "    result = {\n",
    "        \"Output\": output_name,\n",
    "        \"Best Alpha (Overall)\": best_alpha, \n",
    "        \"R2 Score\": R2_Score,\n",
    "        \"MAE\": MAE,\n",
    "        \"MSE\": MSE,\n",
    "        \"RMSE\": RMSE,\n",
    "        \"RMSLE\": RMSLE,\n",
    "        \"MAPE\": MAPE,\n",
    "        \"Count < 0.15\": count_below_threshold,\n",
    "        \"Percentage Below Threshold\": percentage_below_threshold\n",
    "    }\n",
    "    results_list.append(result)\n",
    "\n",
    "    print(f\"  Output: {output_name}, R2: {R2_Score:.4f}, MAE: {MAE:.4f}, MSE: {MSE:.4f}, MAPE: {MAPE:.4f}, Percentage Below Threshold: {percentage_below_threshold:.4%}\")\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "output_csv_path = \"Results/ridge_multioutput_regression_results_v2.csv\" \n",
    "results_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"\\nFinal multi-output results saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f340bbe-2c6c-4b93-80cd-95b5ea7687aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "model_filename = 'models/rigde_multioutput_model.sav'\n",
    "joblib.dump(final_model, model_filename)\n",
    "\n",
    "print(f\"Model saved to {model_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b16dd91-d3a2-40ae-98e8-eb1500f0a68b",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaf0c1b-86b9-425e-acac-237fd4357a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "epsilon = 1e-6\n",
    "\n",
    "# --- GRID SEARCH FOR XGBOOST BASELINE ---\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [10, 20, 50, 100, 200],\n",
    "    'estimator__max_depth': [3, 4, 5, 6, 7],\n",
    "    'estimator__learning_rate': [0.01, 0.05, 0.1]\n",
    "    # 'estimator__subsample': [0.8, 1.0],\n",
    "    # 'estimator__colsample_bytree': [0.8, 1.0],\n",
    "}\n",
    "param_list = list(ParameterGrid(param_grid))\n",
    "\n",
    "print(\"Optimizing hyperparameters for MultiOutputRegressor(XGBRegressor)...\")\n",
    "print(f\"Grid size: {len(param_list)} combinations.\")\n",
    "\n",
    "param_search_results = []\n",
    "\n",
    "# Khởi tạo mô hình cơ sở XGBoost một lần\n",
    "base_xgb = XGBRegressor(objective='reg:squarederror', tree_method=\"gpu_hist\") \n",
    "multi_output_model = MultiOutputRegressor(base_xgb, n_jobs=-1)\n",
    "\n",
    "\n",
    "for i, params in enumerate(param_list):\n",
    "    print(f\"  Testing params combination {i+1}/{len(param_list)}: {params}\")\n",
    "\n",
    "    multi_output_model.set_params(**params)\n",
    "\n",
    "    try:\n",
    "        multi_output_model.fit(trainX, trainy)\n",
    "        val_pre_full = multi_output_model.predict(testX)\n",
    "        avg_mae = mean_absolute_error(testy, val_pre_full)\n",
    "        param_search_results.append(avg_mae)\n",
    "        print(f\"    Average MAE: {avg_mae:.5f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ERROR during training/prediction with params {params}: {e}\")\n",
    "        param_search_results.append(np.inf)\n",
    "\n",
    "if not param_search_results or all(np.isinf(param_search_results)):\n",
    "    print(\"\\nERROR: Hyperparameter search failed for all combinations.\")\n",
    "    exit()\n",
    "\n",
    "min_avg_mae = min(param_search_results)\n",
    "min_indices = [i for i, mae in enumerate(param_search_results) if mae == min_avg_mae]\n",
    "min_index = min_indices[0]\n",
    "\n",
    "best_params_overall = param_list[min_index]\n",
    "print(f\"\\nBest overall parameters found: {best_params_overall}\")\n",
    "print(f\"Based on minimum average MAE: {min_avg_mae:.5f}\")\n",
    "\n",
    "print(\"\\nTraining final MultiOutputRegressor model using the best parameters...\")\n",
    "final_base_xgb = XGBRegressor(objective='reg:squarederror', tree_method=\"gpu_hist\")\n",
    "final_multi_output_model = MultiOutputRegressor(final_base_xgb, n_jobs=-1)\n",
    "final_multi_output_model.set_params(**best_params_overall)\n",
    "\n",
    "\n",
    "final_multi_output_model.fit(trainX, trainy)\n",
    "val_pre_full = final_multi_output_model.predict(testX) # Kết quả là 2D\n",
    "results_list = []\n",
    "print(\"\\nCalculating metrics for each output using the single trained MultiOutputRegressor...\")\n",
    "for idx, output_name in enumerate(list_dongvi):\n",
    "    testy_output = testy[:, idx]\n",
    "    val_pre_output = val_pre_full[:, idx] \n",
    "\n",
    "    MAE = mean_absolute_error(testy_output, val_pre_output)\n",
    "    MSE = mean_squared_error(testy_output, val_pre_output)\n",
    "    RMSE = np.sqrt(MSE)\n",
    "    RMSLE = np.log(RMSE + epsilon) if RMSE >= 0 else np.nan\n",
    "    R2_Score = r2_score(testy_output, val_pre_output)\n",
    "    MAPE = mean_absolute_percentage_error(testy_output + epsilon, val_pre_output)\n",
    "\n",
    "    percentage_errors = np.abs((testy_output - val_pre_output) / (testy_output + epsilon))\n",
    "    count_below_threshold = np.sum(percentage_errors < 0.15)\n",
    "    percentage_below_threshold = count_below_threshold / len(testy_output) if len(testy_output) > 0 else 0\n",
    "\n",
    "    best_params_str = str(best_params_overall)\n",
    "    result = {\n",
    "        \"Output\": output_name,\n",
    "        \"Best Params (Overall)\": best_params_str, \n",
    "        \"R2 Score\": R2_Score,\n",
    "        \"MAE\": MAE,\n",
    "        \"MSE\": MSE,\n",
    "        \"RMSE\": RMSE,\n",
    "        \"RMSLE\": RMSLE,\n",
    "        \"MAPE\": MAPE,\n",
    "        \"Count < 0.15\": count_below_threshold,\n",
    "        \"Percentage Below Threshold\": percentage_below_threshold\n",
    "    }\n",
    "    results_list.append(result)\n",
    "    print(f\"  Output: {output_name}, R2: {R2_Score:.4f}, MAE: {MAE:.4f}, MSE: {MSE:.4f}, MAPE: {MAPE:.4f}, Percentage Below Threshold: {percentage_below_threshold:.4%}\")\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "output_csv_path = \"Results/xgboost_MultiOutputRegressor_results.csv\" # Đổi tên file cho rõ ràng\n",
    "results_df.to_csv(output_csv_path, index=False)\n",
    "print(f\"\\nFinal MultiOutputRegressor results saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a62fe6-fcf5-4126-bc69-5851aa6ab683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "model_filename = 'models/xgboost_multioutput_model.sav'\n",
    "joblib.dump(final_model, model_filename)\n",
    "\n",
    "print(f\"Model saved to {model_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DVPX",
   "language": "python",
   "name": "dvpx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
